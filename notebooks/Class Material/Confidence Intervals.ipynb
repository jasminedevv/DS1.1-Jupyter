{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals & Outliers\n",
    "\n",
    "## Learning Objectives (Competencies)\n",
    "By the end of this lesson, students will be able to:\n",
    "1. Describe confidence interval and when and how apply to a sample data\n",
    "2. Describe what is outlier and how to remove outlier for univariate data\n",
    "3. Visualize the outliers by box-plot\n",
    "\n",
    "\n",
    "## What is confidence interval?\n",
    "\n",
    "It is useful to estimate an interval for the possible values of the parameter and put a probability on how confident we are that the true parameter value falls inside this interval\n",
    "\n",
    "## Example\n",
    "We have the data X and assume we know the population standard deviation ($\\sigma$). What is confidence interval for population mean?\n",
    "$P(L &lt; \\mu &lt; U) = 1 - \\alpha$\n",
    "We want to obtain $L$ and $U$, with 1-$\\alpha$ confidence\n",
    "\n",
    "# From Statistics references\n",
    "$L = \\bar{x} - z_{1- \\alpha/2}\\frac{\\sigma}{\\sqrt{N}}$\n",
    "$U = \\bar{x} + z_{1- \\alpha/2}\\frac{\\sigma}{\\sqrt{N}}$\n",
    "\n",
    "## Activity: Obtain the confidence interval for mean of sepal length for Setosa\n",
    "The dataset we will work is iris.cvs\n",
    "Tasks:\n",
    "1- Explore this dataset. How many features, records and plants does it have?\n",
    "2- Gather all of the sepal length for Iris-Setosa\n",
    "3- Write a function that calculate lower and upper bound for mean of sepal length for Iris-Setosa with %95 confidence.\n",
    "Assume $\\sigma = 0.3525$\n",
    "Hint: use scipy.stats.norm.ppf() to calculate $z_{1- \\alpha/2}$\n",
    "\n",
    "```Python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "df = pd.read_csv('Iris.csv')\n",
    "\n",
    "x = df[df['Species'] == 'Iris-setosa']['SepalLengthCm'].tolist()\n",
    "\n",
    "print(np.mean(x))\n",
    "\n",
    "def ci_z(data_sample, significant_level, sigma):\n",
    "    z = scipy.stats.norm.ppf(1-significant_level/2)\n",
    "    L = np.mean(data_sample) - z*sigma/np.sqrt(len(data_sample))\n",
    "    U = np.mean(data_sample) + z*sigma/np.sqrt(len(data_sample))\n",
    "    return L, U\n",
    "\n",
    "\n",
    "def ci_t(data_sample, significant_level):\n",
    "    t = scipy.stats.t.ppf(1 - significant_level/2, len(data_sample) - 1)\n",
    "    L = np.mean(data_sample) - t * np.std(data_sample, ddof=1) / np.sqrt(len(data_sample))\n",
    "    U = np.mean(data_sample) + t * np.std(data_sample, ddof=1) / np.sqrt(len(data_sample))\n",
    "    return L, U\n",
    "\n",
    "print(ci_z(x, 0.05, 0.3525))\n",
    "print(ci_t(x,0.05))\n",
    "```\n",
    "\n",
    "## Outlier Detection\n",
    "Outliers are extreme values that can skew our dataset, sometimes giving us an incorrect picture of how things actually are in our dataset. The hardest part of this is determining which data points are acceptable, and which ones constitute \"outlier\" status.\n",
    "\n",
    "## Activity: find and remove outliers if our dataset is Normal\n",
    "\n",
    "- When our sample data is close to normal distribution, the samples that be outside of three standard deviation can be considered as outliers.\n",
    "- Task: Write a function that first find outliers for a normally distributed data, then remove them.\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "def find_remove_outlier(data_sample):\n",
    "    # calculate summary statistics\n",
    "    data_mean, data_std = np.mean(data), np.std(data)\n",
    "    # define cut-off\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "    # identify outliers\n",
    "    outliers = [x for x in data_sample if x < lower or x > upper]\n",
    "    # remove outliers\n",
    "    outliers_removed = [x for x in data_sample if x > lower and x < upper]\n",
    "    return outliers, outliers_removed\n",
    "```\n",
    "\n",
    "## Interquartile range (IQR) for finding and removing outlier when data has any distribution (10 min)\n",
    "\n",
    "Tukey suggested to calculate the range between the first quartile (25%) and third quartile (75%) in the data, called the interquartile range (IQR).\n",
    "\n",
    "## Activity: IQR outlier detection and removal\n",
    "Task: write a function to find and remove outliers based on IQR method for this data sample:\n",
    "Hint:\n",
    "$Q_1$ is the first quartile (25%)\n",
    "$Q_3$ is the third quartile (75%)\n",
    "\n",
    "![](../Notebooks/Images/iqr.png)\n",
    "\n",
    "```Python\n",
    "import numpy as np\n",
    "\n",
    "def find_remove_outlier_iqr(data_sample):\n",
    "    # calculate interquartile range\n",
    "    q25, q75 = np.percentile(data_sample, 25), np.percentile(data_sample, 75)\n",
    "    iqr = q75 - q25\n",
    "    # calculate the outlier cutoff\n",
    "    cut_off = iqr * 1.5\n",
    "    lower, upper = q25 - cut_off, q75 + cut_off\n",
    "    # identify outliers\n",
    "    outliers = [x for x in data_sample if x < lower or x > upper]\n",
    "    # remove outliers\n",
    "    outliers_removed = [x for x in data_sample if x > lower and x < upper]\n",
    "    return outliers\n",
    "\n",
    "y = np.array([-5, 11, 14])\n",
    "x =  np.concatenate((scipy.stats.norm.rvs(loc=5 , scale=1 , size=100), y))\n",
    "print(type(x))\n",
    "print(find_remove_outlier_iqr(x))\n",
    "print(scipy.stats.iqr(x))\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## How we can visually see the outlier?Â¶\n",
    "Box plot use the IQR method to display data and outliers\n",
    "```Python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(x)\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "## Resources\n",
    "- Read this assignment from CS department of Utah [Estimation and Confidence Intervals](https://www.cs.utah.edu/~jeffp/teaching/cs3130/homeworks/hw7.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.006\n",
      "(4.908293780383348, 5.103706219616653)\n",
      "(4.905823539430869, 5.106176460569132)\n"
     ]
    }
   ],
   "source": [
    "setosa_lengths = iris[iris['species'] == 'setosa']['sepal_length'].tolist()\n",
    "\n",
    "print(np.mean(setosa_lengths))\n",
    "\n",
    "# confidence interval for a z-test\n",
    "def confidence_interval_z(data_sample, significant_level, sigma):\n",
    "    z_score = scipy.stats.norm.ppf(1-significant_level/2)\n",
    "    L = np.mean(data_sample) - z_score*sigma/np.sqrt(len(data_sample))\n",
    "    U = np.mean(data_sample) + z_score*sigma/np.sqrt(len(data_sample))\n",
    "    return L, U\n",
    "\n",
    "# confidence interval for a t-test\n",
    "def confidence_interval_t(data_sample, significant_level):\n",
    "    t_score = scipy.stats.t.ppf(1 - significant_level/2, len(data_sample) - 1)\n",
    "    L = np.mean(data_sample) - t_score * np.std(data_sample, ddof=1) / np.sqrt(len(data_sample))\n",
    "    U = np.mean(data_sample) + t_score * np.std(data_sample, ddof=1) / np.sqrt(len(data_sample))\n",
    "    return L, U\n",
    "\n",
    "print(confidence_interval_z(setosa_lengths, 0.05, 0.3525))\n",
    "print(confidence_interval_t(setosa_lengths,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import mixture\n",
    "\n",
    "# Generate data samples and plot its histogram\n",
    "x_1 = np.random.normal(-5, 1, 3000)\n",
    "x_2 = np.random.normal(2, 3, 7000) \n",
    "x = np.concatenate((x_1, x_2))\n",
    "plt.hist(x, bins=20, density=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrplot_(df=None, mask_type=\"numerical\", figsize=(14, 14), fontsize=8, cpalette=(10, 220)):\n",
    "    \"\"\" Global function that produces customized correlation plot reducing redundancy. \"\"\"    \n",
    "    if df is None:\n",
    "        raise ReferenceError(\"\\nDataFrame not found.\")\n",
    "    corr_data = df.corr()\n",
    "\n",
    "    # Creates whitespace mask over upper right triangle section for repeated features\n",
    "    upper_triangle_mask = np.zeros_like(corr_data, dtype=np.bool)\n",
    "    upper_triangle_mask[np.triu_indices_from(upper_triangle_mask)] = True\n",
    "    \n",
    "    # Generates MatPlotLib subplot objects\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Calculates relative maximum from correlational data\n",
    "    vmax = np.abs(corr_data.values[~upper_triangle_mask]).max()\n",
    "    \n",
    "    # Creates correlational heatmap with simple color intensity relative to distribution\n",
    "    cmap = sns.diverging_palette(cpalette[0], cpalette[1], as_cmap=True)\n",
    "    sns.heatmap(corr_data, mask=upper_triangle_mask, cmap=cmap, vmin=-vmax, vmax=vmax, square=True, linecolor=\"lightgray\", linewidths=1, ax=ax)\n",
    "    \n",
    "    # Overlays feature names and corr. data values over whitespace mask\n",
    "    for iterator in range(len(corr_data)):\n",
    "        ax.text(iterator+0.5, iterator+0.5, corr_data.columns[iterator], ha=\"center\", va=\"center\", rotation=45)\n",
    "        \n",
    "        for jterator in range(iterator+1, len(corr_data)):\n",
    "            value = \"{:.3f}\".format(corr_data.values[iterator, jterator])\n",
    "            \n",
    "            # Switch-case for numerical whitespace mask\n",
    "            if mask_type == \"numerical\":\n",
    "                ax.text(jterator+0.5, (iterator+0.5), value, ha=\"center\", va=\"center\")\n",
    "                \n",
    "            # Switch-case for categorical whitespace mask\n",
    "            if mask_type == \"categorical\":\n",
    "                ax.text(jterator+0.5, (iterator+0.5), _value_to_category(value), ha=\"center\", va=\"center\", fontsize=fontsize)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "def _value_to_category(value):\n",
    "    \"\"\" Helper function to convert numerical values between -1.0 and 1.0 to discretized categories. \"\"\"\n",
    "    _categorical_types, _value_ranges_test = [\"- (S)\", \"- (M)\", \"- (W)\", \"0\", \"+ (W)\", \"+ (M)\", \"+ (S)\"], [-1.0, -0.7, -0.4, -0.1, 0.1, 0.4, 0.7, 1.0]\n",
    "    # Iterates through value ranges and checks if value falls within specific range\n",
    "    for index in range(len(_value_ranges_test) - 1):\n",
    "        if float(value) >= _value_ranges_test[index] and float(value) < _value_ranges_test[index + 1]:\n",
    "            return _categorical_types[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
